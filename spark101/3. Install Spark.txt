1. Download latest Spark for current Hadoop. Decompress them to home director. 

cd ~/Downloads
tar zxvf spark-2.4.4-bin-hadoop2.6.tgz 
mv spark-2.4.4-bin-hadoop2.6 ~/


2. Setup SPARK_HOME and PATH variables in ~/.bashrc

vim ~/.bashrc
---------------------------------
# .bashrc
...

export SPARK_HOME=/home/cloudera/spark-2.4.4-bin-hadoop2.6
export PATH=$SPARK_HOME/bin:$PATH
export PYSPARK_PYTHON=python3
export PYSPARK_DRIVER_PYTHON=ipython3

3. source ~/.bashrc for the settings to take effect

source ~/.bashrc


4. Test it

[cloudera@quickstart ~]$ which spark-submit
~/spark-2.4.4-bin-hadoop2.6/bin/spark-submit

5. Start the spark cluster

cd ~/spark-2.4.4-bin-hadoop2.6/sbin
./start-all.sh

check 
http://localhost:8080

to see if the master and a worker are running

6. Setup spark-shell for exiSpark SQL

# allow cloudera user to access /tmp/hive locally and /tmp/hive in HDFS

sudo chmod 777 -R /tmp/hive

sudo su - hdfs
hadoop fs -chmod -R 777 /tmp/hive
exit

7. test spark-shell

[cloudera@quickstart ~]$ pyspark --master spark://quickstart.cloudera:7077


Python 3.7.3 (default, Mar 27 2019, 22:11:17) 
Type 'copyright', 'credits' or 'license' for more information
IPython 7.6.1 -- An enhanced Interactive Python. Type '?' for help.
19/09/27 04:42:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.4
      /_/

Using Python version 3.7.3 (default, Mar 27 2019 22:11:17)
SparkSession available as 'spark'.

In [1]:                                                                        

